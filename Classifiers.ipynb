{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ML_Project_data.csv')\n",
    "data_model = data.drop(['label'], axis=1)\n",
    "labels = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1)).fit(data_model)\n",
    "data_model_scaled = scaler.transform(data_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19',\n",
       "       'f20', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n",
       "       'f31', 'f33', 'f34', 'f37', 'f40', 'f41', 'f42', 'f44', 'f46',\n",
       "       'f50', 'f52', 'f56', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65',\n",
       "       'f66', 'f67', 'f68'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(data_model.columns)\n",
    "selectModel = SelectKBest(chi2, k=50)\n",
    "selectModel.fit(data_model_scaled, labels)\n",
    "selected_features = selectModel.get_feature_names_out(features)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_cols = dict()\n",
    "selected_cols = []\n",
    "\n",
    "for i in range(len(selected_features)):\n",
    "    col = int(selected_features[i][1:])\n",
    "    deleted_cols[col] = 0\n",
    "\n",
    "for i in range(len(data_model.columns)):\n",
    "    if i not in deleted_cols:\n",
    "        selected_cols.append(i)\n",
    "    \n",
    "\n",
    "data_model_scaled = np.delete(data_model_scaled, selected_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData, testData, trainLabels, testLabels = train_test_split(data_model_scaled, labels, test_size=0.1,  random_state=42)                                                    \n",
    "# trainData, validData, trainLabels, validLabels = train_test_split(trainData, trainLabels, test_size=0.15,  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(model):\n",
    "    print(\"TrainData: \")\n",
    "    print(classification_report(trainLabels, model.predict(trainData)))\n",
    "    \n",
    "    print(\"TestData: \")\n",
    "    print(classification_report(testLabels, model.predict(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.56047502\n",
      "Iteration 2, loss = 1.47224479\n",
      "Iteration 3, loss = 1.42586080\n",
      "Iteration 4, loss = 1.37974651\n",
      "Iteration 5, loss = 1.34643339\n",
      "Iteration 6, loss = 1.31424212\n",
      "Iteration 7, loss = 1.28042896\n",
      "Iteration 8, loss = 1.25766729\n",
      "Iteration 9, loss = 1.23098971\n",
      "Iteration 10, loss = 1.20510741\n",
      "Iteration 11, loss = 1.18338763\n",
      "Iteration 12, loss = 1.16194079\n",
      "Iteration 13, loss = 1.13526774\n",
      "Iteration 14, loss = 1.11784326\n",
      "Iteration 15, loss = 1.09858100\n",
      "Iteration 16, loss = 1.07407899\n",
      "Iteration 17, loss = 1.06065167\n",
      "Iteration 18, loss = 1.03517444\n",
      "Iteration 19, loss = 1.01618276\n",
      "Iteration 20, loss = 1.00227939\n",
      "Iteration 21, loss = 0.97861959\n",
      "Iteration 22, loss = 0.96990347\n",
      "Iteration 23, loss = 0.94273121\n",
      "Iteration 24, loss = 0.93786440\n",
      "Iteration 25, loss = 0.92143999\n",
      "Iteration 26, loss = 0.90140890\n",
      "Iteration 27, loss = 0.89234286\n",
      "Iteration 28, loss = 0.87903041\n",
      "Iteration 29, loss = 0.86062311\n",
      "Iteration 30, loss = 0.85130761\n",
      "Iteration 31, loss = 0.83564563\n",
      "Iteration 32, loss = 0.83177601\n",
      "Iteration 33, loss = 0.81648785\n",
      "Iteration 34, loss = 0.79862694\n",
      "Iteration 35, loss = 0.78327119\n",
      "Iteration 36, loss = 0.76883809\n",
      "Iteration 37, loss = 0.76077853\n",
      "Iteration 38, loss = 0.75554946\n",
      "Iteration 39, loss = 0.73594881\n",
      "Iteration 40, loss = 0.73020259\n",
      "Iteration 41, loss = 0.71154016\n",
      "Iteration 42, loss = 0.70437491\n",
      "Iteration 43, loss = 0.69613696\n",
      "Iteration 44, loss = 0.68667124\n",
      "Iteration 45, loss = 0.67817325\n",
      "Iteration 46, loss = 0.66755311\n",
      "Iteration 47, loss = 0.65905235\n",
      "Iteration 48, loss = 0.64103795\n",
      "Iteration 49, loss = 0.63184090\n",
      "Iteration 50, loss = 0.63392773\n",
      "Iteration 51, loss = 0.62058843\n",
      "Iteration 52, loss = 0.62293119\n",
      "Iteration 53, loss = 0.59768134\n",
      "Iteration 54, loss = 0.59868724\n",
      "Iteration 55, loss = 0.59216518\n",
      "Iteration 56, loss = 0.57708275\n",
      "Iteration 57, loss = 0.56146167\n",
      "Iteration 58, loss = 0.55887045\n",
      "Iteration 59, loss = 0.55400137\n",
      "Iteration 60, loss = 0.55213984\n",
      "Iteration 61, loss = 0.54993148\n",
      "Iteration 62, loss = 0.53058521\n",
      "Iteration 63, loss = 0.52795968\n",
      "Iteration 64, loss = 0.53673669\n",
      "Iteration 65, loss = 0.51537547\n",
      "Iteration 66, loss = 0.50260137\n",
      "Iteration 67, loss = 0.51588227\n",
      "Iteration 68, loss = 0.49766534\n",
      "Iteration 69, loss = 0.48696940\n",
      "Iteration 70, loss = 0.49466161\n",
      "Iteration 71, loss = 0.49123788\n",
      "Iteration 72, loss = 0.47570151\n",
      "Iteration 73, loss = 0.48518020\n",
      "Iteration 74, loss = 0.46312228\n",
      "Iteration 75, loss = 0.44599710\n",
      "Iteration 76, loss = 0.45764260\n",
      "Iteration 77, loss = 0.44915575\n",
      "Iteration 78, loss = 0.45986174\n",
      "Iteration 79, loss = 0.44348088\n",
      "Iteration 80, loss = 0.43918177\n",
      "Iteration 81, loss = 0.42771272\n",
      "Iteration 82, loss = 0.41767286\n",
      "Iteration 83, loss = 0.43354786\n",
      "Iteration 84, loss = 0.41043785\n",
      "Iteration 85, loss = 0.40675064\n",
      "Iteration 86, loss = 0.41566096\n",
      "Iteration 87, loss = 0.39877897\n",
      "Iteration 88, loss = 0.40143261\n",
      "Iteration 89, loss = 0.39199993\n",
      "Iteration 90, loss = 0.38883415\n",
      "Iteration 91, loss = 0.37775702\n",
      "Iteration 92, loss = 0.37961445\n",
      "Iteration 93, loss = 0.38549962\n",
      "Iteration 94, loss = 0.36472009\n",
      "Iteration 95, loss = 0.37799592\n",
      "Iteration 96, loss = 0.37083453\n",
      "Iteration 97, loss = 0.36660409\n",
      "Iteration 98, loss = 0.36355239\n",
      "Iteration 99, loss = 0.34231323\n",
      "Iteration 100, loss = 0.34645046\n",
      "Iteration 101, loss = 0.34209935\n",
      "Iteration 102, loss = 0.34351467\n",
      "Iteration 103, loss = 0.35454520\n",
      "Iteration 104, loss = 0.32775375\n",
      "Iteration 105, loss = 0.31640969\n",
      "Iteration 106, loss = 0.31961502\n",
      "Iteration 107, loss = 0.34080386\n",
      "Iteration 108, loss = 0.34628311\n",
      "Iteration 109, loss = 0.31811072\n",
      "Iteration 110, loss = 0.34223199\n",
      "Iteration 111, loss = 0.30882765\n",
      "Iteration 112, loss = 0.31476776\n",
      "Iteration 113, loss = 0.30494105\n",
      "Iteration 114, loss = 0.30405176\n",
      "Iteration 115, loss = 0.29770364\n",
      "Iteration 116, loss = 0.29026016\n",
      "Iteration 117, loss = 0.28982368\n",
      "Iteration 118, loss = 0.28654422\n",
      "Iteration 119, loss = 0.29123967\n",
      "Iteration 120, loss = 0.29123637\n",
      "Iteration 121, loss = 0.28446089\n",
      "Iteration 122, loss = 0.28095580\n",
      "Iteration 123, loss = 0.27046862\n",
      "Iteration 124, loss = 0.26586553\n",
      "Iteration 125, loss = 0.26571152\n",
      "Iteration 126, loss = 0.28192610\n",
      "Iteration 127, loss = 0.27648826\n",
      "Iteration 128, loss = 0.25958313\n",
      "Iteration 129, loss = 0.26628280\n",
      "Iteration 130, loss = 0.26199471\n",
      "Iteration 131, loss = 0.24932697\n",
      "Iteration 132, loss = 0.27001062\n",
      "Iteration 133, loss = 0.26704799\n",
      "Iteration 134, loss = 0.27546326\n",
      "Iteration 135, loss = 0.23197876\n",
      "Iteration 136, loss = 0.24880129\n",
      "Iteration 137, loss = 0.27183585\n",
      "Iteration 138, loss = 0.24741344\n",
      "Iteration 139, loss = 0.24366716\n",
      "Iteration 140, loss = 0.23400932\n",
      "Iteration 141, loss = 0.23417029\n",
      "Iteration 142, loss = 0.23714124\n",
      "Iteration 143, loss = 0.22114901\n",
      "Iteration 144, loss = 0.24390101\n",
      "Iteration 145, loss = 0.22860628\n",
      "Iteration 146, loss = 0.23054284\n",
      "Iteration 147, loss = 0.22676820\n",
      "Iteration 148, loss = 0.22901868\n",
      "Iteration 149, loss = 0.24792516\n",
      "Iteration 150, loss = 0.21715015\n",
      "Iteration 151, loss = 0.20595784\n",
      "Iteration 152, loss = 0.21142983\n",
      "Iteration 153, loss = 0.23810449\n",
      "Iteration 154, loss = 0.22388132\n",
      "Iteration 155, loss = 0.19270265\n",
      "Iteration 156, loss = 0.22310302\n",
      "Iteration 157, loss = 0.21059344\n",
      "Iteration 158, loss = 0.18725727\n",
      "Iteration 159, loss = 0.22012846\n",
      "Iteration 160, loss = 0.21582176\n",
      "Iteration 161, loss = 0.22194718\n",
      "Iteration 162, loss = 0.19601881\n",
      "Iteration 163, loss = 0.20815954\n",
      "Iteration 164, loss = 0.19538883\n",
      "Iteration 165, loss = 0.21905514\n",
      "Iteration 166, loss = 0.19035632\n",
      "Iteration 167, loss = 0.20959764\n",
      "Iteration 168, loss = 0.17384054\n",
      "Iteration 169, loss = 0.22153918\n",
      "Iteration 170, loss = 0.20259793\n",
      "Iteration 171, loss = 0.20557736\n",
      "Iteration 172, loss = 0.18582337\n",
      "Iteration 173, loss = 0.14758384\n",
      "Iteration 174, loss = 0.17936021\n",
      "Iteration 175, loss = 0.20190264\n",
      "Iteration 176, loss = 0.21718995\n",
      "Iteration 177, loss = 0.17324367\n",
      "Iteration 178, loss = 0.20675738\n",
      "Iteration 179, loss = 0.16730607\n",
      "Iteration 180, loss = 0.18656348\n",
      "Iteration 181, loss = 0.21023121\n",
      "Iteration 182, loss = 0.16499475\n",
      "Iteration 183, loss = 0.18754754\n",
      "Iteration 184, loss = 0.16142831\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=32, hidden_layer_sizes=(128, 64, 32, 16),\n",
       "              learning_rate_init=0.01, max_iter=350, momentum=0.85,\n",
       "              random_state=4, solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes = (128, 64, 32, 16), solver = 'sgd', batch_size = 32, random_state=4, \\\n",
    "                      verbose=True, momentum=0.85, max_iter=350, learning_rate_init = 0.01)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549745824255628"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892156862745098"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      2243\n",
      "           1       0.98      0.94      0.96      2082\n",
      "           2       0.97      0.94      0.95      2320\n",
      "           3       0.94      0.97      0.96      2384\n",
      "           4       0.95      0.95      0.95      1987\n",
      "\n",
      "    accuracy                           0.95     11016\n",
      "   macro avg       0.96      0.95      0.96     11016\n",
      "weighted avg       0.96      0.95      0.96     11016\n",
      "\n",
      "TestData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       254\n",
      "           1       0.84      0.76      0.80       239\n",
      "           2       0.83      0.79      0.81       286\n",
      "           3       0.71      0.83      0.76       241\n",
      "           4       0.77      0.73      0.75       204\n",
      "\n",
      "    accuracy                           0.79      1224\n",
      "   macro avg       0.79      0.79      0.79      1224\n",
      "weighted avg       0.79      0.79      0.79      1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='ball_tree', metric='manhattan', n_neighbors=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='manhattan', algorithm='ball_tree')\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9240196078431373"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2243\n",
      "           1       1.00      1.00      1.00      2082\n",
      "           2       1.00      1.00      1.00      2320\n",
      "           3       1.00      1.00      1.00      2384\n",
      "           4       1.00      1.00      1.00      1987\n",
      "\n",
      "    accuracy                           1.00     11016\n",
      "   macro avg       1.00      1.00      1.00     11016\n",
      "weighted avg       1.00      1.00      1.00     11016\n",
      "\n",
      "TestData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       254\n",
      "           1       0.93      0.93      0.93       239\n",
      "           2       0.94      0.90      0.92       286\n",
      "           3       0.93      0.93      0.93       241\n",
      "           4       0.91      0.92      0.91       204\n",
      "\n",
      "    accuracy                           0.92      1224\n",
      "   macro avg       0.92      0.92      0.92      1224\n",
      "weighted avg       0.92      0.92      0.92      1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NuSVC(decision_function_shape='ovo', gamma=4, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NuSVC(kernel=\"rbf\", gamma=4, decision_function_shape='ovo', random_state=42, verbose=True)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89960058097313"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7826797385620915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      2243\n",
      "           1       0.94      0.88      0.91      2082\n",
      "           2       0.94      0.93      0.94      2320\n",
      "           3       0.90      0.90      0.90      2384\n",
      "           4       0.88      0.92      0.90      1987\n",
      "\n",
      "    accuracy                           0.90     11016\n",
      "   macro avg       0.90      0.90      0.90     11016\n",
      "weighted avg       0.90      0.90      0.90     11016\n",
      "\n",
      "TestData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       254\n",
      "           1       0.86      0.74      0.80       239\n",
      "           2       0.86      0.79      0.82       286\n",
      "           3       0.70      0.83      0.76       241\n",
      "           4       0.74      0.77      0.75       204\n",
      "\n",
      "    accuracy                           0.78      1224\n",
      "   macro avg       0.79      0.78      0.78      1224\n",
      "weighted avg       0.79      0.78      0.78      1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, decision_function_shape='ovo', gamma=8, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', C=1, gamma=8, decision_function_shape='ovo', random_state=42)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954611474219317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521241830065359"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2243\n",
      "           1       1.00      0.99      1.00      2082\n",
      "           2       1.00      0.99      1.00      2320\n",
      "           3       1.00      0.99      1.00      2384\n",
      "           4       0.99      1.00      0.99      1987\n",
      "\n",
      "    accuracy                           1.00     11016\n",
      "   macro avg       1.00      1.00      1.00     11016\n",
      "weighted avg       1.00      1.00      1.00     11016\n",
      "\n",
      "TestData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       254\n",
      "           1       0.92      0.81      0.86       239\n",
      "           2       0.93      0.85      0.88       286\n",
      "           3       0.68      0.94      0.79       241\n",
      "           4       0.90      0.80      0.85       204\n",
      "\n",
      "    accuracy                           0.85      1224\n",
      "   macro avg       0.87      0.85      0.85      1224\n",
      "weighted avg       0.87      0.85      0.86      1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, min_samples_split=3, n_estimators=80,\n",
       "                       oob_score=True, random_state=42, warm_start=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth=30, n_estimators=80, random_state=42, warm_start=True, min_samples_split=3 \\\n",
    "                              , bootstrap=True, oob_score=True)\n",
    "model.fit(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(trainData, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924836601307189"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(testData, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2243\n",
      "           1       1.00      1.00      1.00      2082\n",
      "           2       1.00      1.00      1.00      2320\n",
      "           3       1.00      1.00      1.00      2384\n",
      "           4       1.00      1.00      1.00      1987\n",
      "\n",
      "    accuracy                           1.00     11016\n",
      "   macro avg       1.00      1.00      1.00     11016\n",
      "weighted avg       1.00      1.00      1.00     11016\n",
      "\n",
      "TestData: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81       254\n",
      "           1       0.89      0.77      0.82       239\n",
      "           2       0.82      0.80      0.81       286\n",
      "           3       0.72      0.79      0.75       241\n",
      "           4       0.74      0.76      0.75       204\n",
      "\n",
      "    accuracy                           0.79      1224\n",
      "   macro avg       0.79      0.79      0.79      1224\n",
      "weighted avg       0.80      0.79      0.79      1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
