{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boIpwhxo-158",
        "outputId": "c50cf1bf-3ec1-4760-8341-1e7db5822056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mutagen\n",
            "  Downloading mutagen-1.45.1-py3-none-any.whl (218 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30 kB 41.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 40 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 71 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 218 kB 7.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: mutagen\n",
            "Successfully installed mutagen-1.45.1\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install mutagen\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "!apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9odR7dEn_n6g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import json\n",
        "import librosa\n",
        "from numpy.lib.utils import source\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from mutagen.mp3 import MP3\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import mediainfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF5MQJG4ACrn"
      },
      "outputs": [],
      "source": [
        "def createDirectoryIfDoesNotExists(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def getAllMusicsTimeInSeconds(data_path, bad_files):\n",
        "    result = []\n",
        "\n",
        "    for subdir, dirs, files in os.walk(DATA_PATH):\n",
        "        for file in tqdm(files):\n",
        "            filePath = DATA_PATH + os.sep + subdir.split(os.sep)[-1] + os.sep + file   \n",
        "\n",
        "            try:\n",
        "              audio = MP3(filePath)\n",
        "              result.append(int(audio.info.length))\n",
        "            except:\n",
        "              bad_files.append(filePath)\n",
        "              pass\n",
        "    return result\n",
        "\n",
        "def splitMusics(data_path, final_path, category, lengthInMilliseconds):\n",
        "    print(f\"Splitting {category}\")\n",
        "    result = []\n",
        "    category_path = join(data_path, category)\n",
        "\n",
        "    files = [f for f in listdir(category_path) if isfile(join(category_path, f))]\n",
        "\n",
        "    for file in tqdm(files):\n",
        "        splittedFile = file.split('.')\n",
        "        fileName = \".\".join(splittedFile[:-1])\n",
        "\n",
        "        filePath = join(category_path, file)\n",
        "\n",
        "        if(filePath in bad_files):\n",
        "          continue\n",
        "\n",
        "        sound = AudioSegment.from_file(filePath)\n",
        "\n",
        "        soundLength = len(sound)\n",
        "        numberOfParts = soundLength // lengthInMilliseconds\n",
        "        loss = soundLength - numberOfParts * lengthInMilliseconds\n",
        "        skipEnd = loss // 2\n",
        "        skipStart = loss - skipEnd\n",
        "\n",
        "        start = skipStart + 1\n",
        "        for i in range(numberOfParts):\n",
        "            partFilePath = join(final_path, category, fileName + \"_\" + str(i+1) + \".wav\")\n",
        "            part = sound[start: start+lengthInMilliseconds+1]\n",
        "\n",
        "            createDirectoryIfDoesNotExists(join(final_path, category))\n",
        "\n",
        "            part.export(partFilePath , format=\"wav\")\n",
        "            start = start+lengthInMilliseconds+1          \n",
        "\n",
        "\n",
        "def prepare_dataset(data_path, category, n_mfcc=13, hop_length=512, n_fft=2048):\n",
        "    SAMPLES_TO_CONSIDER = 22050 * 30\n",
        "\n",
        "    label = {\"Bandari\":0, \"Gilaki\":1, \"Kordi\":2, \"Lori\":3, \"Torki\":4}\n",
        "    category_path = join(data_path, category)\n",
        "\n",
        "    files = [f for f in listdir(category_path) if isfile(join(category_path, f))]\n",
        "\n",
        "    # data[\"mappings\"].append(category)\n",
        "    print(f\"Processing {category}\")\n",
        "\n",
        "    for file in tqdm(files):\n",
        "\n",
        "      file_path = join(category_path, file)\n",
        "\n",
        "      signal, sr = librosa.load(file_path)\n",
        "\n",
        "      if len(signal) >= SAMPLES_TO_CONSIDER:\n",
        "          signal = signal[:SAMPLES_TO_CONSIDER]\n",
        "\n",
        "          features = []\n",
        "\n",
        "          #zero crossing\n",
        "          zero_crossing = librosa.zero_crossings(signal, pad = False)\n",
        "          features.append(zero_crossing.sum())\n",
        "\n",
        "          #spectral centroids\n",
        "          spectral_centroids = librosa.feature.spectral_centroid(signal, sr=sr)[0]\n",
        "          features.append(spectral_centroids.mean())\n",
        "          features.append(spectral_centroids.var())\n",
        "\n",
        "          #spectral rolloff\n",
        "          spectral_rolloff = librosa.feature.spectral_rolloff(signal+0.01, sr=sr)[0]\n",
        "          features.append(spectral_rolloff.mean())\n",
        "          features.append(spectral_rolloff.var())\n",
        "\n",
        "          #Chroma Frequencies\n",
        "          chromagram = librosa.feature.chroma_stft(signal, sr=sr, hop_length=hop_length)\n",
        "          features += chromagram.mean(axis=1).tolist()\n",
        "          features += chromagram.var(axis=1).tolist()\n",
        "          \n",
        "          #Mel-Frequency Cepstral Coefficients\n",
        "          MFCCs = librosa.feature.mfcc(signal, hop_length=hop_length, n_fft=n_fft)\n",
        "          features += MFCCs.mean(axis=1).tolist()\n",
        "          features += MFCCs.var(axis=1).tolist()\n",
        "\n",
        "          # add label\n",
        "          features.append(label[category])\n",
        "\n",
        "          data.append(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m22XAwied1Ol"
      },
      "outputs": [],
      "source": [
        "!unrar x \"/content/drive/MyDrive/ML_course_data_gathering_Arash_Rasouli/ML_Data G1.rar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQy60G_KgFdu",
        "outputId": "3bd492e0-3176-409a-a487-2ad4436b355f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 267/267 [00:01<00:00, 137.16it/s]\n",
            "100%|██████████| 276/276 [00:02<00:00, 98.55it/s]\n",
            "100%|██████████| 289/289 [00:01<00:00, 162.81it/s]\n",
            "100%|██████████| 280/280 [00:03<00:00, 70.99it/s] \n",
            "100%|██████████| 271/271 [00:01<00:00, 169.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "['/content/ML_Data G1/Bandari/22.mp3', '/content/ML_Data G1/Torki/104.mp3', '/content/ML_Data G1/Torki/231.mp3', '/content/ML_Data G1/Lori/156.mp3', '/content/ML_Data G1/Lori/89.mp3']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "bad_files = []\n",
        "DATA_PATH = \"/content/ML_Data G1\"\n",
        "getAllMusicsTimeInSeconds(DATA_PATH, bad_files)\n",
        "print(\"\\n\")\n",
        "print(bad_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oCJa-UEoEAT9"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/ML_Data G1\"\n",
        "final_path = \"/content/all\"\n",
        "\n",
        "csv_header = [\"f\"+str(i) for i in range(69)] + [\"label\"]\n",
        "csv_header = \",\".join(csv_header)\n",
        "\n",
        "# add your categories\n",
        "# categories = [\"Bandari\", \"Gilaki\", \"Kordi\", \"Lori\", \"Torki\"]\n",
        "\n",
        "categories = [\"Lori\", \"Torki\"]\n",
        "\n",
        "for category in categories:\n",
        "  data = []\n",
        "\n",
        "  splitMusics(data_path, final_path, category, 30000)\n",
        "  prepare_dataset(final_path, category)\n",
        "  shutil.rmtree(join(final_path, category))\n",
        "\n",
        "  csv_path = \"/content/drive/MyDrive/ML_Data/\" + category + '.csv'\n",
        "\n",
        "  np.savetxt(csv_path, data, delimiter=\",\", header=csv_header, comments=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Bandari = pd.read_csv('/content/drive/MyDrive/ML_Data/Bandari.csv')\n",
        "Gilaki = pd.read_csv('/content/drive/MyDrive/ML_Data/Gilaki.csv')\n",
        "Kordi = pd.read_csv('/content/drive/MyDrive/ML_Data/Kordi.csv')\n",
        "Lori = pd.read_csv('/content/drive/MyDrive/ML_Data/Lori.csv')\n",
        "Torki = pd.read_csv('/content/drive/MyDrive/ML_Data/Torki.csv')\n",
        "\n",
        "all = pd.concat([Bandari, Gilaki, Kordi, Lori, Torki])\n",
        "all.reset_index()\n",
        "\n",
        "all.to_csv('/content/drive/MyDrive/ML_Data/ML_Project_Data.csv')"
      ],
      "metadata": {
        "id": "_y9rWMfhsChf"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PreProcessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}